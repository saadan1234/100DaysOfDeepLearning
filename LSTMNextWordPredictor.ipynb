{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNVjkL/Y2viPjPuFdTGu9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadan1234/100DaysOfDeepLearning/blob/main/LSTMNextWordPredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profile Data"
      ],
      "metadata": {
        "id": "WgrtTiJlU4Qt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "data = \"\"\"Hi there! I'm Muhammad Saadan, a Software Engineer.\n",
        "For demo videos of projects, research, and work, please visit my LinkedIn profile.\n",
        "Welcome to my Crafting Laboratory\n",
        "Key Contributions\n",
        "Optical Networks and Technologies Lab\n",
        "Improved the accuracy of GSNR predictions using Machine Learning techniques like Transfer Learning, Active Learning, Knowledge Distillation, and Federated Learning, achieving a mean squared error (MSE) of 0.00002.\n",
        "Machine Learning Internship Experience\n",
        "Worked as a Machine Learning Intern at CodSoft and INTERNSAVY through virtual internships. Developed and tested predictive models for various domains such as Fraud detection, Customer segmentation, and Graduate Admission Prediction.\n",
        "Education & Certifications\n",
        "Pursuing a Bachelor of Engineering in Software Engineering at the National University of Sciences and Technology (NUST), focusing on Deep Learning and Federated Learning. Completed certifications in Big Data, AWS, and Machine Learning from Coursera.\n",
        "Future Aspirations\n",
        "I aim to keep growing in Deep Learning and AI, focusing on research and crafting practical solutions. Currently, working on a project regarding the implementation of federated learning with enhanced usability.\n",
        "Popular repositories\n",
        "FL: Testing PySyft and experimenting with federated learning.\n",
        "CodSoft-MachineLearning: Machine Learning tasks.\n",
        "Certifications: Certifications and Letters.\n",
        "InternSavy-MachineLearning: Machine Learning tasks.\n",
        "SafeSteps_ComputerVision: An automatic pedestrian and people detection system utilizing YOLOv8.\n",
        "Optical-Network-and-Technologies: Research in Optical Network and Technologies Lab NUST.\n",
        "Contact\n",
        "Email: msaadan.bese21seecs@seecs.edu.pk\n",
        "GitHub: saadan1234\n",
        "Number: +92 332 9297757\n",
        "LinkedIn: Muhammad Saadan\n",
        "Kaggle: saadan1234\n",
        "Education\n",
        "Software Engineering (2021-2025)\n",
        "National University of Sciences and Technology (H-12)\n",
        "CGPA: 3.32\n",
        "Experience\n",
        "National Database and Registration Authority\n",
        "Network Security Intern\n",
        "Configured and implemented Network Access Control, Firewalls, IP subnetting, and VPN. Gained an understanding of NADRA’s network communication.\n",
        "Optical Network and Technologies Lab\n",
        "Deep Learning Researcher\n",
        "Accurately predicted GSNR Ratio with MSE less than 0.001. Tested models with Transfer Learning, Active Learning, Federated Learning, and Knowledge Distillation using TensorFlow, PyTorch, Keras, scikit-learn.\n",
        "Internships\n",
        "Machine Learning Intern | Frontend Intern (Virtual)\n",
        "Developed predictive models for various tasks and built a personal portfolio website. Utilized Pandas, matplotlib, scikit-learn, seaborn, nltk.\n",
        "Projects\n",
        "Image Generation App\n",
        "Developed an image generation app using OpenAIApi and “Dall-e 3” model. Stack: React, Node, MongoDB, Cloudinary, Express.js.\n",
        "Chatbot\n",
        "Developed a chatbot app using OpenAIApi and “gpt 3.5 turbo” model. Stack: React, Node, MongoDB, Express.js.\n",
        "RAG-App\n",
        "Developed an end-to-end RAG-APP for PDF document processing and response generation. Libraries: langchain, PyPDF, ChromaDB, Flask, Ollama Server.\n",
        "Safe Steps\n",
        "Developed a custom model using YOLOv8 for detecting crosswalks. Libraries: OpenCV(cv2), NumPy, Flask.\n",
        "Skills\n",
        "Languages | Frameworks: Python, HTML, CSS, JavaScript, Typescript, Tailwindcss, React, Flwr\n",
        "Platforms: Google Colab, Jupyter Notebook, Kaggle, Roboflow, VSCode, Apache Jmeter, Matlab, HuggingFace, MongoDB, Cloudinary.\n",
        "Volunteer Work\n",
        "Pakistan Red Crescent Society (PRCS), H-12.\n",
        "Certifications\n",
        "1. AWS Solution Architect (Amazon)\n",
        "2. Machine Learning Specialization\n",
        "3. Deep Learning Specialization (Stanford, DeepLearning.AI)\n",
        "4. Google Cloud Big Data and ML Fundamentals\n",
        "5. Meta Front End Fundamentals\n",
        "6. Federated Learning (DeepLearning.AI)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing"
      ],
      "metadata": {
        "id": "Id67SFcoU9G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "J1D42emD32Ro"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "KhtDxwL_AXFj"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "K8MRFre9AaG9"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenizer.word_index))\n",
        "print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrpAl3EDAgvh",
        "outputId": "8ae18964-daf0-4d00-9562-cccb40c980dc"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275\n",
            "{'and': 1, 'learning': 2, 'a': 3, 'of': 4, 'machine': 5, 'federated': 6, 'developed': 7, 'network': 8, 'for': 9, 'using': 10, 'certifications': 11, 'app': 12, 'optical': 13, 'technologies': 14, 'intern': 15, 'in': 16, 'deep': 17, 'with': 18, 'an': 19, 'software': 20, 'research': 21, 'to': 22, 'lab': 23, 'the': 24, 'models': 25, 'engineering': 26, 'national': 27, 'on': 28, 'ai': 29, 'tasks': 30, '3': 31, 'generation': 32, 'model': 33, 'react': 34, 'mongodb': 35, 'end': 36, 'muhammad': 37, 'saadan': 38, 'projects': 39, 'work': 40, 'my': 41, 'linkedin': 42, 'crafting': 43, 'gsnr': 44, 'transfer': 45, 'active': 46, 'knowledge': 47, 'distillation': 48, 'mse': 49, '0': 50, 'experience': 51, 'as': 52, 'at': 53, 'codsoft': 54, 'internsavy': 55, 'virtual': 56, 'internships': 57, 'tested': 58, 'predictive': 59, 'various': 60, 'detection': 61, 'education': 62, 'university': 63, 'sciences': 64, 'technology': 65, 'nust': 66, 'focusing': 67, 'big': 68, 'data': 69, 'aws': 70, 'machinelearning': 71, 'yolov8': 72, 'saadan1234': 73, 'kaggle': 74, 'h': 75, '12': 76, 'scikit': 77, 'learn': 78, 'image': 79, 'openaiapi': 80, 'stack': 81, 'node': 82, 'cloudinary': 83, 'express': 84, 'js': 85, 'chatbot': 86, '5': 87, 'rag': 88, 'libraries': 89, 'flask': 90, 'google': 91, 'specialization': 92, 'deeplearning': 93, 'fundamentals': 94, 'hi': 95, 'there': 96, \"i'm\": 97, 'engineer': 98, 'demo': 99, 'videos': 100, 'please': 101, 'visit': 102, 'profile': 103, 'welcome': 104, 'laboratory': 105, 'key': 106, 'contributions': 107, 'networks': 108, 'improved': 109, 'accuracy': 110, 'predictions': 111, 'techniques': 112, 'like': 113, 'achieving': 114, 'mean': 115, 'squared': 116, 'error': 117, '00002': 118, 'internship': 119, 'worked': 120, 'through': 121, 'domains': 122, 'such': 123, 'fraud': 124, 'customer': 125, 'segmentation': 126, 'graduate': 127, 'admission': 128, 'prediction': 129, 'pursuing': 130, 'bachelor': 131, 'completed': 132, 'from': 133, 'coursera': 134, 'future': 135, 'aspirations': 136, 'i': 137, 'aim': 138, 'keep': 139, 'growing': 140, 'practical': 141, 'solutions': 142, 'currently': 143, 'working': 144, 'project': 145, 'regarding': 146, 'implementation': 147, 'enhanced': 148, 'usability': 149, 'popular': 150, 'repositories': 151, 'fl': 152, 'testing': 153, 'pysyft': 154, 'experimenting': 155, 'letters': 156, 'safesteps': 157, 'computervision': 158, 'automatic': 159, 'pedestrian': 160, 'people': 161, 'system': 162, 'utilizing': 163, 'contact': 164, 'email': 165, 'msaadan': 166, 'bese21seecs': 167, 'seecs': 168, 'edu': 169, 'pk': 170, 'github': 171, 'number': 172, '92': 173, '332': 174, '9297757': 175, '2021': 176, '2025': 177, 'cgpa': 178, '32': 179, 'database': 180, 'registration': 181, 'authority': 182, 'security': 183, 'configured': 184, 'implemented': 185, 'access': 186, 'control': 187, 'firewalls': 188, 'ip': 189, 'subnetting': 190, 'vpn': 191, 'gained': 192, 'understanding': 193, 'nadra’s': 194, 'communication': 195, 'researcher': 196, 'accurately': 197, 'predicted': 198, 'ratio': 199, 'less': 200, 'than': 201, '001': 202, 'tensorflow': 203, 'pytorch': 204, 'keras': 205, 'frontend': 206, 'built': 207, 'personal': 208, 'portfolio': 209, 'website': 210, 'utilized': 211, 'pandas': 212, 'matplotlib': 213, 'seaborn': 214, 'nltk': 215, '“dall': 216, 'e': 217, '3”': 218, '“gpt': 219, 'turbo”': 220, 'pdf': 221, 'document': 222, 'processing': 223, 'response': 224, 'langchain': 225, 'pypdf': 226, 'chromadb': 227, 'ollama': 228, 'server': 229, 'safe': 230, 'steps': 231, 'custom': 232, 'detecting': 233, 'crosswalks': 234, 'opencv': 235, 'cv2': 236, 'numpy': 237, 'skills': 238, 'languages': 239, 'frameworks': 240, 'python': 241, 'html': 242, 'css': 243, 'javascript': 244, 'typescript': 245, 'tailwindcss': 246, 'flwr': 247, 'platforms': 248, 'colab': 249, 'jupyter': 250, 'notebook': 251, 'roboflow': 252, 'vscode': 253, 'apache': 254, 'jmeter': 255, 'matlab': 256, 'huggingface': 257, 'volunteer': 258, 'pakistan': 259, 'red': 260, 'crescent': 261, 'society': 262, 'prcs': 263, '1': 264, 'solution': 265, 'architect': 266, 'amazon': 267, '2': 268, 'stanford': 269, '4': 270, 'cloud': 271, 'ml': 272, 'meta': 273, 'front': 274, '6': 275}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in data.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "44VahqKdAjr9"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in data.split('\\n\\n'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2JaY8LAXUAJ",
        "outputId": "f94dd188-9a74-4adf-89cb-385ed59332d3"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! I'm Muhammad Saadan, a Software Engineer.\n",
            "For demo videos of projects, research, and work, please visit my LinkedIn profile.\n",
            "Welcome to my Crafting Laboratory\n",
            "Key Contributions\n",
            "Optical Networks and Technologies Lab\n",
            "Improved the accuracy of GSNR predictions using Machine Learning techniques like Transfer Learning, Active Learning, Knowledge Distillation, and Federated Learning, achieving a mean squared error (MSE) of 0.00002.\n",
            "Machine Learning Internship Experience\n",
            "Worked as a Machine Learning Intern at CodSoft and INTERNSAVY through virtual internships. Developed and tested predictive models for various domains such as Fraud detection, Customer segmentation, and Graduate Admission Prediction.\n",
            "Education & Certifications\n",
            "Pursuing a Bachelor of Engineering in Software Engineering at the National University of Sciences and Technology (NUST), focusing on Deep Learning and Federated Learning. Completed certifications in Big Data, AWS, and Machine Learning from Coursera.\n",
            "Future Aspirations\n",
            "I aim to keep growing in Deep Learning and AI, focusing on research and crafting practical solutions. Currently, working on a project regarding the implementation of federated learning with enhanced usability.\n",
            "Popular repositories\n",
            "FL: Testing PySyft and experimenting with federated learning.\n",
            "CodSoft-MachineLearning: Machine Learning tasks.\n",
            "Certifications: Certifications and Letters.\n",
            "InternSavy-MachineLearning: Machine Learning tasks.\n",
            "SafeSteps_ComputerVision: An automatic pedestrian and people detection system utilizing YOLOv8.\n",
            "Optical-Network-and-Technologies: Research in Optical Network and Technologies Lab NUST.\n",
            "Contact\n",
            "Email: msaadan.bese21seecs@seecs.edu.pk\n",
            "GitHub: saadan1234\n",
            "Number: +92 332 9297757\n",
            "LinkedIn: Muhammad Saadan\n",
            "Kaggle: saadan1234\n",
            "Education\n",
            "Software Engineering (2021-2025)\n",
            "National University of Sciences and Technology (H-12)\n",
            "CGPA: 3.32\n",
            "Experience\n",
            "National Database and Registration Authority\n",
            "Network Security Intern \n",
            "Configured and implemented Network Access Control, Firewalls, IP subnetting, and VPN. Gained an understanding of NADRA’s network communication.\n",
            "Optical Network and Technologies Lab\n",
            "Deep Learning Researcher \n",
            "Accurately predicted GSNR Ratio with MSE less than 0.001. Tested models with Transfer Learning, Active Learning, Federated Learning, and Knowledge Distillation using TensorFlow, PyTorch, Keras, scikit-learn.\n",
            "Internships\n",
            "Machine Learning Intern | Frontend Intern (Virtual)\n",
            "Developed predictive models for various tasks and built a personal portfolio website. Utilized Pandas, matplotlib, scikit-learn, seaborn, nltk.\n",
            "Projects\n",
            "Image Generation App\n",
            "Developed an image generation app using OpenAIApi and “Dall-e 3” model. Stack: React, Node, MongoDB, Cloudinary, Express.js.\n",
            "Chatbot\n",
            "Developed a chatbot app using OpenAIApi and “gpt 3.5 turbo” model. Stack: React, Node, MongoDB, Express.js.\n",
            "RAG-App\n",
            "Developed an end-to-end RAG-APP for PDF document processing and response generation. Libraries: langchain, PyPDF, ChromaDB, Flask, Ollama Server.\n",
            "Safe Steps\n",
            "Developed a custom model using YOLOv8 for detecting crosswalks. Libraries: OpenCV(cv2), NumPy, Flask.\n",
            "Skills\n",
            "Languages | Frameworks: Python, HTML, CSS, JavaScript, Typescript, Tailwindcss, React, Flwr\n",
            "Platforms: Google Colab, Jupyter Notebook, Kaggle, Roboflow, VSCode, Apache Jmeter, Matlab, HuggingFace, MongoDB, Cloudinary.\n",
            "Volunteer Work\n",
            "Pakistan Red Crescent Society (PRCS), H-12.\n",
            "Certifications\n",
            "1. AWS Solution Architect (Amazon)\n",
            "2. Machine Learning Specialization\n",
            "3. Deep Learning Specialization (Stanford, DeepLearning.AI)\n",
            "4. Google Cloud Big Data and ML Fundamentals\n",
            "5. Meta Front End Fundamentals\n",
            "6. Federated Learning (DeepLearning.AI)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqwPDzNA5mR",
        "outputId": "6ce98eaf-2d44-46b6-97db-46e28a3a16cf"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[95, 96],\n",
              " [95, 96, 97],\n",
              " [95, 96, 97, 37],\n",
              " [95, 96, 97, 37, 38],\n",
              " [95, 96, 97, 37, 38, 3],\n",
              " [95, 96, 97, 37, 38, 3, 20],\n",
              " [95, 96, 97, 37, 38, 3, 20, 98],\n",
              " [9, 99],\n",
              " [9, 99, 100],\n",
              " [9, 99, 100, 4],\n",
              " [9, 99, 100, 4, 39],\n",
              " [9, 99, 100, 4, 39, 21],\n",
              " [9, 99, 100, 4, 39, 21, 1],\n",
              " [9, 99, 100, 4, 39, 21, 1, 40],\n",
              " [9, 99, 100, 4, 39, 21, 1, 40, 101],\n",
              " [9, 99, 100, 4, 39, 21, 1, 40, 101, 102],\n",
              " [9, 99, 100, 4, 39, 21, 1, 40, 101, 102, 41],\n",
              " [9, 99, 100, 4, 39, 21, 1, 40, 101, 102, 41, 42],\n",
              " [9, 99, 100, 4, 39, 21, 1, 40, 101, 102, 41, 42, 103],\n",
              " [104, 22],\n",
              " [104, 22, 41],\n",
              " [104, 22, 41, 43],\n",
              " [104, 22, 41, 43, 105],\n",
              " [106, 107],\n",
              " [13, 108],\n",
              " [13, 108, 1],\n",
              " [13, 108, 1, 14],\n",
              " [13, 108, 1, 14, 23],\n",
              " [109, 24],\n",
              " [109, 24, 110],\n",
              " [109, 24, 110, 4],\n",
              " [109, 24, 110, 4, 44],\n",
              " [109, 24, 110, 4, 44, 111],\n",
              " [109, 24, 110, 4, 44, 111, 10],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46, 2],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46, 2, 47],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46, 2, 47, 48],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46, 2, 47, 48, 1],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46, 2, 47, 48, 1, 6],\n",
              " [109, 24, 110, 4, 44, 111, 10, 5, 2, 112, 113, 45, 2, 46, 2, 47, 48, 1, 6, 2],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115,\n",
              "  116],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115,\n",
              "  116,\n",
              "  117],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  49],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  49,\n",
              "  4],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  49,\n",
              "  4,\n",
              "  50],\n",
              " [109,\n",
              "  24,\n",
              "  110,\n",
              "  4,\n",
              "  44,\n",
              "  111,\n",
              "  10,\n",
              "  5,\n",
              "  2,\n",
              "  112,\n",
              "  113,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  47,\n",
              "  48,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  114,\n",
              "  3,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  49,\n",
              "  4,\n",
              "  50,\n",
              "  118],\n",
              " [5, 2],\n",
              " [5, 2, 119],\n",
              " [5, 2, 119, 51],\n",
              " [120, 52],\n",
              " [120, 52, 3],\n",
              " [120, 52, 3, 5],\n",
              " [120, 52, 3, 5, 2],\n",
              " [120, 52, 3, 5, 2, 15],\n",
              " [120, 52, 3, 5, 2, 15, 53],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7, 1],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7, 1, 58],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7, 1, 58, 59],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7, 1, 58, 59, 25],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7, 1, 58, 59, 25, 9],\n",
              " [120, 52, 3, 5, 2, 15, 53, 54, 1, 55, 121, 56, 57, 7, 1, 58, 59, 25, 9, 60],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61,\n",
              "  125],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61,\n",
              "  125,\n",
              "  126],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61,\n",
              "  125,\n",
              "  126,\n",
              "  1],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61,\n",
              "  125,\n",
              "  126,\n",
              "  1,\n",
              "  127],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61,\n",
              "  125,\n",
              "  126,\n",
              "  1,\n",
              "  127,\n",
              "  128],\n",
              " [120,\n",
              "  52,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  15,\n",
              "  53,\n",
              "  54,\n",
              "  1,\n",
              "  55,\n",
              "  121,\n",
              "  56,\n",
              "  57,\n",
              "  7,\n",
              "  1,\n",
              "  58,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  122,\n",
              "  123,\n",
              "  52,\n",
              "  124,\n",
              "  61,\n",
              "  125,\n",
              "  126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  129],\n",
              " [62, 11],\n",
              " [130, 3],\n",
              " [130, 3, 131],\n",
              " [130, 3, 131, 4],\n",
              " [130, 3, 131, 4, 26],\n",
              " [130, 3, 131, 4, 26, 16],\n",
              " [130, 3, 131, 4, 26, 16, 20],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4, 64],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4, 64, 1],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4, 64, 1, 65],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4, 64, 1, 65, 66],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4, 64, 1, 65, 66, 67],\n",
              " [130, 3, 131, 4, 26, 16, 20, 26, 53, 24, 27, 63, 4, 64, 1, 65, 66, 67, 28],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69,\n",
              "  70],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  1],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  1,\n",
              "  5],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  1,\n",
              "  5,\n",
              "  2],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  133],\n",
              " [130,\n",
              "  3,\n",
              "  131,\n",
              "  4,\n",
              "  26,\n",
              "  16,\n",
              "  20,\n",
              "  26,\n",
              "  53,\n",
              "  24,\n",
              "  27,\n",
              "  63,\n",
              "  4,\n",
              "  64,\n",
              "  1,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  28,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  132,\n",
              "  11,\n",
              "  16,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  1,\n",
              "  5,\n",
              "  2,\n",
              "  133,\n",
              "  134],\n",
              " [135, 136],\n",
              " [137, 138],\n",
              " [137, 138, 22],\n",
              " [137, 138, 22, 139],\n",
              " [137, 138, 22, 139, 140],\n",
              " [137, 138, 22, 139, 140, 16],\n",
              " [137, 138, 22, 139, 140, 16, 17],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28, 21],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28, 21, 1],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28, 21, 1, 43],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28, 21, 1, 43, 141],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28, 21, 1, 43, 141, 142],\n",
              " [137, 138, 22, 139, 140, 16, 17, 2, 1, 29, 67, 28, 21, 1, 43, 141, 142, 143],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147,\n",
              "  4],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147,\n",
              "  4,\n",
              "  6],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147,\n",
              "  4,\n",
              "  6,\n",
              "  2],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  18],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  18,\n",
              "  148],\n",
              " [137,\n",
              "  138,\n",
              "  22,\n",
              "  139,\n",
              "  140,\n",
              "  16,\n",
              "  17,\n",
              "  2,\n",
              "  1,\n",
              "  29,\n",
              "  67,\n",
              "  28,\n",
              "  21,\n",
              "  1,\n",
              "  43,\n",
              "  141,\n",
              "  142,\n",
              "  143,\n",
              "  144,\n",
              "  28,\n",
              "  3,\n",
              "  145,\n",
              "  146,\n",
              "  24,\n",
              "  147,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  18,\n",
              "  148,\n",
              "  149],\n",
              " [150, 151],\n",
              " [152, 153],\n",
              " [152, 153, 154],\n",
              " [152, 153, 154, 1],\n",
              " [152, 153, 154, 1, 155],\n",
              " [152, 153, 154, 1, 155, 18],\n",
              " [152, 153, 154, 1, 155, 18, 6],\n",
              " [152, 153, 154, 1, 155, 18, 6, 2],\n",
              " [54, 71],\n",
              " [54, 71, 5],\n",
              " [54, 71, 5, 2],\n",
              " [54, 71, 5, 2, 30],\n",
              " [11, 11],\n",
              " [11, 11, 1],\n",
              " [11, 11, 1, 156],\n",
              " [55, 71],\n",
              " [55, 71, 5],\n",
              " [55, 71, 5, 2],\n",
              " [55, 71, 5, 2, 30],\n",
              " [157, 158],\n",
              " [157, 158, 19],\n",
              " [157, 158, 19, 159],\n",
              " [157, 158, 19, 159, 160],\n",
              " [157, 158, 19, 159, 160, 1],\n",
              " [157, 158, 19, 159, 160, 1, 161],\n",
              " [157, 158, 19, 159, 160, 1, 161, 61],\n",
              " [157, 158, 19, 159, 160, 1, 161, 61, 162],\n",
              " [157, 158, 19, 159, 160, 1, 161, 61, 162, 163],\n",
              " [157, 158, 19, 159, 160, 1, 161, 61, 162, 163, 72],\n",
              " [13, 8],\n",
              " [13, 8, 1],\n",
              " [13, 8, 1, 14],\n",
              " [13, 8, 1, 14, 21],\n",
              " [13, 8, 1, 14, 21, 16],\n",
              " [13, 8, 1, 14, 21, 16, 13],\n",
              " [13, 8, 1, 14, 21, 16, 13, 8],\n",
              " [13, 8, 1, 14, 21, 16, 13, 8, 1],\n",
              " [13, 8, 1, 14, 21, 16, 13, 8, 1, 14],\n",
              " [13, 8, 1, 14, 21, 16, 13, 8, 1, 14, 23],\n",
              " [13, 8, 1, 14, 21, 16, 13, 8, 1, 14, 23, 66],\n",
              " [165, 166],\n",
              " [165, 166, 167],\n",
              " [165, 166, 167, 168],\n",
              " [165, 166, 167, 168, 169],\n",
              " [165, 166, 167, 168, 169, 170],\n",
              " [171, 73],\n",
              " [172, 173],\n",
              " [172, 173, 174],\n",
              " [172, 173, 174, 175],\n",
              " [42, 37],\n",
              " [42, 37, 38],\n",
              " [74, 73],\n",
              " [20, 26],\n",
              " [20, 26, 176],\n",
              " [20, 26, 176, 177],\n",
              " [27, 63],\n",
              " [27, 63, 4],\n",
              " [27, 63, 4, 64],\n",
              " [27, 63, 4, 64, 1],\n",
              " [27, 63, 4, 64, 1, 65],\n",
              " [27, 63, 4, 64, 1, 65, 75],\n",
              " [27, 63, 4, 64, 1, 65, 75, 76],\n",
              " [178, 31],\n",
              " [178, 31, 179],\n",
              " [27, 180],\n",
              " [27, 180, 1],\n",
              " [27, 180, 1, 181],\n",
              " [27, 180, 1, 181, 182],\n",
              " [8, 183],\n",
              " [8, 183, 15],\n",
              " [184, 1],\n",
              " [184, 1, 185],\n",
              " [184, 1, 185, 8],\n",
              " [184, 1, 185, 8, 186],\n",
              " [184, 1, 185, 8, 186, 187],\n",
              " [184, 1, 185, 8, 186, 187, 188],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191, 192],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191, 192, 19],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191, 192, 19, 193],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191, 192, 19, 193, 4],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191, 192, 19, 193, 4, 194],\n",
              " [184, 1, 185, 8, 186, 187, 188, 189, 190, 1, 191, 192, 19, 193, 4, 194, 8],\n",
              " [184,\n",
              "  1,\n",
              "  185,\n",
              "  8,\n",
              "  186,\n",
              "  187,\n",
              "  188,\n",
              "  189,\n",
              "  190,\n",
              "  1,\n",
              "  191,\n",
              "  192,\n",
              "  19,\n",
              "  193,\n",
              "  4,\n",
              "  194,\n",
              "  8,\n",
              "  195],\n",
              " [13, 8],\n",
              " [13, 8, 1],\n",
              " [13, 8, 1, 14],\n",
              " [13, 8, 1, 14, 23],\n",
              " [17, 2],\n",
              " [17, 2, 196],\n",
              " [197, 198],\n",
              " [197, 198, 44],\n",
              " [197, 198, 44, 199],\n",
              " [197, 198, 44, 199, 18],\n",
              " [197, 198, 44, 199, 18, 49],\n",
              " [197, 198, 44, 199, 18, 49, 200],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25, 18],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25, 18, 45],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25, 18, 45, 2],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25, 18, 45, 2, 46],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25, 18, 45, 2, 46, 2],\n",
              " [197, 198, 44, 199, 18, 49, 200, 201, 50, 202, 58, 25, 18, 45, 2, 46, 2, 6],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48,\n",
              "  10],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48,\n",
              "  10,\n",
              "  203],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48,\n",
              "  10,\n",
              "  203,\n",
              "  204],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48,\n",
              "  10,\n",
              "  203,\n",
              "  204,\n",
              "  205],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48,\n",
              "  10,\n",
              "  203,\n",
              "  204,\n",
              "  205,\n",
              "  77],\n",
              " [197,\n",
              "  198,\n",
              "  44,\n",
              "  199,\n",
              "  18,\n",
              "  49,\n",
              "  200,\n",
              "  201,\n",
              "  50,\n",
              "  202,\n",
              "  58,\n",
              "  25,\n",
              "  18,\n",
              "  45,\n",
              "  2,\n",
              "  46,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  47,\n",
              "  48,\n",
              "  10,\n",
              "  203,\n",
              "  204,\n",
              "  205,\n",
              "  77,\n",
              "  78],\n",
              " [5, 2],\n",
              " [5, 2, 15],\n",
              " [5, 2, 15, 206],\n",
              " [5, 2, 15, 206, 15],\n",
              " [5, 2, 15, 206, 15, 56],\n",
              " [7, 59],\n",
              " [7, 59, 25],\n",
              " [7, 59, 25, 9],\n",
              " [7, 59, 25, 9, 60],\n",
              " [7, 59, 25, 9, 60, 30],\n",
              " [7, 59, 25, 9, 60, 30, 1],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210, 211],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210, 211, 212],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210, 211, 212, 213],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210, 211, 212, 213, 77],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210, 211, 212, 213, 77, 78],\n",
              " [7, 59, 25, 9, 60, 30, 1, 207, 3, 208, 209, 210, 211, 212, 213, 77, 78, 214],\n",
              " [7,\n",
              "  59,\n",
              "  25,\n",
              "  9,\n",
              "  60,\n",
              "  30,\n",
              "  1,\n",
              "  207,\n",
              "  3,\n",
              "  208,\n",
              "  209,\n",
              "  210,\n",
              "  211,\n",
              "  212,\n",
              "  213,\n",
              "  77,\n",
              "  78,\n",
              "  214,\n",
              "  215],\n",
              " [79, 32],\n",
              " [79, 32, 12],\n",
              " [7, 19],\n",
              " [7, 19, 79],\n",
              " [7, 19, 79, 32],\n",
              " [7, 19, 79, 32, 12],\n",
              " [7, 19, 79, 32, 12, 10],\n",
              " [7, 19, 79, 32, 12, 10, 80],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81, 34],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81, 34, 82],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81, 34, 82, 35],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81, 34, 82, 35, 83],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81, 34, 82, 35, 83, 84],\n",
              " [7, 19, 79, 32, 12, 10, 80, 1, 216, 217, 218, 33, 81, 34, 82, 35, 83, 84, 85],\n",
              " [7, 3],\n",
              " [7, 3, 86],\n",
              " [7, 3, 86, 12],\n",
              " [7, 3, 86, 12, 10],\n",
              " [7, 3, 86, 12, 10, 80],\n",
              " [7, 3, 86, 12, 10, 80, 1],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33, 81],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33, 81, 34],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33, 81, 34, 82],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33, 81, 34, 82, 35],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33, 81, 34, 82, 35, 84],\n",
              " [7, 3, 86, 12, 10, 80, 1, 219, 31, 87, 220, 33, 81, 34, 82, 35, 84, 85],\n",
              " [88, 12],\n",
              " [7, 19],\n",
              " [7, 19, 36],\n",
              " [7, 19, 36, 22],\n",
              " [7, 19, 36, 22, 36],\n",
              " [7, 19, 36, 22, 36, 88],\n",
              " [7, 19, 36, 22, 36, 88, 12],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1, 224],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1, 224, 32],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1, 224, 32, 89],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1, 224, 32, 89, 225],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1, 224, 32, 89, 225, 226],\n",
              " [7, 19, 36, 22, 36, 88, 12, 9, 221, 222, 223, 1, 224, 32, 89, 225, 226, 227],\n",
              " [7,\n",
              "  19,\n",
              "  36,\n",
              "  22,\n",
              "  36,\n",
              "  88,\n",
              "  12,\n",
              "  9,\n",
              "  221,\n",
              "  222,\n",
              "  223,\n",
              "  1,\n",
              "  224,\n",
              "  32,\n",
              "  89,\n",
              "  225,\n",
              "  226,\n",
              "  227,\n",
              "  90],\n",
              " [7,\n",
              "  19,\n",
              "  36,\n",
              "  22,\n",
              "  36,\n",
              "  88,\n",
              "  12,\n",
              "  9,\n",
              "  221,\n",
              "  222,\n",
              "  223,\n",
              "  1,\n",
              "  224,\n",
              "  32,\n",
              "  89,\n",
              "  225,\n",
              "  226,\n",
              "  227,\n",
              "  90,\n",
              "  228],\n",
              " [7,\n",
              "  19,\n",
              "  36,\n",
              "  22,\n",
              "  36,\n",
              "  88,\n",
              "  12,\n",
              "  9,\n",
              "  221,\n",
              "  222,\n",
              "  223,\n",
              "  1,\n",
              "  224,\n",
              "  32,\n",
              "  89,\n",
              "  225,\n",
              "  226,\n",
              "  227,\n",
              "  90,\n",
              "  228,\n",
              "  229],\n",
              " [230, 231],\n",
              " [7, 3],\n",
              " [7, 3, 232],\n",
              " [7, 3, 232, 33],\n",
              " [7, 3, 232, 33, 10],\n",
              " [7, 3, 232, 33, 10, 72],\n",
              " [7, 3, 232, 33, 10, 72, 9],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233, 234],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233, 234, 89],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233, 234, 89, 235],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233, 234, 89, 235, 236],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233, 234, 89, 235, 236, 237],\n",
              " [7, 3, 232, 33, 10, 72, 9, 233, 234, 89, 235, 236, 237, 90],\n",
              " [239, 240],\n",
              " [239, 240, 241],\n",
              " [239, 240, 241, 242],\n",
              " [239, 240, 241, 242, 243],\n",
              " [239, 240, 241, 242, 243, 244],\n",
              " [239, 240, 241, 242, 243, 244, 245],\n",
              " [239, 240, 241, 242, 243, 244, 245, 246],\n",
              " [239, 240, 241, 242, 243, 244, 245, 246, 34],\n",
              " [239, 240, 241, 242, 243, 244, 245, 246, 34, 247],\n",
              " [248, 91],\n",
              " [248, 91, 249],\n",
              " [248, 91, 249, 250],\n",
              " [248, 91, 249, 250, 251],\n",
              " [248, 91, 249, 250, 251, 74],\n",
              " [248, 91, 249, 250, 251, 74, 252],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253, 254],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253, 254, 255],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253, 254, 255, 256],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253, 254, 255, 256, 257],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253, 254, 255, 256, 257, 35],\n",
              " [248, 91, 249, 250, 251, 74, 252, 253, 254, 255, 256, 257, 35, 83],\n",
              " [258, 40],\n",
              " [259, 260],\n",
              " [259, 260, 261],\n",
              " [259, 260, 261, 262],\n",
              " [259, 260, 261, 262, 263],\n",
              " [259, 260, 261, 262, 263, 75],\n",
              " [259, 260, 261, 262, 263, 75, 76],\n",
              " [264, 70],\n",
              " [264, 70, 265],\n",
              " [264, 70, 265, 266],\n",
              " [264, 70, 265, 266, 267],\n",
              " [268, 5],\n",
              " [268, 5, 2],\n",
              " [268, 5, 2, 92],\n",
              " [31, 17],\n",
              " [31, 17, 2],\n",
              " [31, 17, 2, 92],\n",
              " [31, 17, 2, 92, 269],\n",
              " [31, 17, 2, 92, 269, 93],\n",
              " [31, 17, 2, 92, 269, 93, 29],\n",
              " [270, 91],\n",
              " [270, 91, 271],\n",
              " [270, 91, 271, 68],\n",
              " [270, 91, 271, 68, 69],\n",
              " [270, 91, 271, 68, 69, 1],\n",
              " [270, 91, 271, 68, 69, 1, 272],\n",
              " [270, 91, 271, 68, 69, 1, 272, 94],\n",
              " [87, 273],\n",
              " [87, 273, 274],\n",
              " [87, 273, 274, 36],\n",
              " [87, 273, 274, 36, 94],\n",
              " [275, 6],\n",
              " [275, 6, 2],\n",
              " [275, 6, 2, 93],\n",
              " [275, 6, 2, 93, 29]]"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "CrzbvUUQCXPU"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMap1904Y0gX",
        "outputId": "b9cf75ec-c6d8-4e55-f6f4-762c4c44712a"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equalizing Input"
      ],
      "metadata": {
        "id": "XQyfJ0kNVP-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "9oPMoWBSD1_U"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miRb-QZyIi7_",
        "outputId": "7928a37a-2827-41df-b312-c29272d6e23b"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  95,  96],\n",
              "       [  0,   0,   0, ...,  95,  96,  97],\n",
              "       [  0,   0,   0, ...,  96,  97,  37],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 275,   6,   2],\n",
              "       [  0,   0,   0, ...,   6,   2,  93],\n",
              "       [  0,   0,   0, ...,   2,  93,  29]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "qVI0-UUrIsd3"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "lXrYHTDFI3uE"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmsFnHx1Qdow",
        "outputId": "61c3965d-ef66-4921-94a1-758b6537e0a7"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(427, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wyYqYgZSeck",
        "outputId": "ca793d87-d08b-431e-9e7a-4eb53df7e377"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(427,)"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=(len(tokenizer.word_index)+1))"
      ],
      "metadata": {
        "id": "rs1NPitwSgzk"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMJ0I6xSiZf",
        "outputId": "0771b5d1-f868-47b6-e945-d6c5ad2217ba"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(427, 276)"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation"
      ],
      "metadata": {
        "id": "1uFcwx6EVgRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "9kVeTvR2S8Fk"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Creation\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=X.shape[1]))  # Correct input_length\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "model.build((X.shape[0],  X.shape[1]))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wo-OYfHpTK2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "8183b46e-4c06-416d-e0ea-2b56dff3fdd3"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_35\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_35\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_33 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;34m427\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │          \u001b[38;5;34m27,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_62 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;34m427\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m150\u001b[0m)              │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_63 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;34m427\u001b[0m, \u001b[38;5;34m150\u001b[0m)                  │         \u001b[38;5;34m180,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m427\u001b[0m, \u001b[38;5;34m276\u001b[0m)                  │          \u001b[38;5;34m41,676\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">180,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">427</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">276</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,676</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m400,476\u001b[0m (1.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">400,476</span> (1.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m400,476\u001b[0m (1.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">400,476</span> (1.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# y does not need reshaping if it's already one-hot encoded\n",
        "print(X.shape)  # Expected shape: (batch_size, timesteps, features)\n",
        "print(y.shape)  # Expected shape: (batch_size, total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJWm3IdlgcSD",
        "outputId": "0ca52381-63a7-4b58-8abf-1b821d427979"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(427, 34)\n",
            "(427, 276)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmu80UldaKIW",
        "outputId": "71eb148f-d00d-4031-cbaa-8b53d096070a"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(427, 34)\n",
            "(427, 276)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFUCALCfJRR",
        "outputId": "64da9069-21c7-4e87-af84-0709d478792c"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - accuracy: 0.1157 - loss: 3.7316\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - accuracy: 0.1628 - loss: 3.6459\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.1366 - loss: 3.5709\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.1338 - loss: 3.5104\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 0.1977 - loss: 3.3735\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.2275 - loss: 3.1771\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 185ms/step - accuracy: 0.1914 - loss: 3.2097\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.2649 - loss: 3.1174\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.2943 - loss: 2.9793\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.3171 - loss: 2.8705\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.3265 - loss: 2.7676\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 0.3393 - loss: 2.7477\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.3997 - loss: 2.5697\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.4117 - loss: 2.5060\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.4249 - loss: 2.4226\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.4361 - loss: 2.3231\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - accuracy: 0.4867 - loss: 2.2982\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5170 - loss: 2.2141\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.5322 - loss: 2.1728\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.5673 - loss: 2.0358\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5900 - loss: 2.0505\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 253ms/step - accuracy: 0.5895 - loss: 1.9954\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.6728 - loss: 1.8769\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.6194 - loss: 1.9014\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.6657 - loss: 1.7919\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.6892 - loss: 1.7232\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - accuracy: 0.7259 - loss: 1.5836\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.7507 - loss: 1.5435\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.7558 - loss: 1.5403\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.7780 - loss: 1.4596\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.7764 - loss: 1.4401\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 200ms/step - accuracy: 0.7708 - loss: 1.4019\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 0.8111 - loss: 1.3336\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.8154 - loss: 1.3056\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.7881 - loss: 1.3324\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8318 - loss: 1.2320\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - accuracy: 0.8136 - loss: 1.2060\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8292 - loss: 1.1800\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.8176 - loss: 1.1690\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.8557 - loss: 1.0832\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8529 - loss: 1.0339\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - accuracy: 0.8616 - loss: 1.0376\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8455 - loss: 1.0096\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8457 - loss: 0.9818\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.8555 - loss: 0.9918\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.8768 - loss: 0.8999\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9023 - loss: 0.8280\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 197ms/step - accuracy: 0.8857 - loss: 0.8743\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.8741 - loss: 0.8823\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9019 - loss: 0.8076\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.8935 - loss: 0.7915\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - accuracy: 0.9140 - loss: 0.7614\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.9063 - loss: 0.7506\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.9090 - loss: 0.7460\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9192 - loss: 0.7118\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9290 - loss: 0.6711\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.9120 - loss: 0.6625\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.9295 - loss: 0.6280\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9095 - loss: 0.6378\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9073 - loss: 0.6419\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.9286 - loss: 0.5876\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9272 - loss: 0.6221\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 243ms/step - accuracy: 0.9428 - loss: 0.5372\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.9216 - loss: 0.5730\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.9321 - loss: 0.5213\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9509 - loss: 0.4888\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.9486 - loss: 0.4926\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.9391 - loss: 0.4871\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9550 - loss: 0.4563\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9417 - loss: 0.4851\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - accuracy: 0.9340 - loss: 0.4730\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 0.9440 - loss: 0.4552\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.9248 - loss: 0.4374\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9415 - loss: 0.4362\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9667 - loss: 0.3799\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9573 - loss: 0.3995\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - accuracy: 0.9505 - loss: 0.3877\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.9674 - loss: 0.3748\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9587 - loss: 0.3669\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9570 - loss: 0.3467\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9395 - loss: 0.3713\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - accuracy: 0.9633 - loss: 0.3146\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - accuracy: 0.9720 - loss: 0.3226\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9588 - loss: 0.3060\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9651 - loss: 0.3315\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 174ms/step - accuracy: 0.9527 - loss: 0.3173\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.9618 - loss: 0.3264\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.9537 - loss: 0.3148\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9520 - loss: 0.3027\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9738 - loss: 0.2885\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9596 - loss: 0.2961\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.9811 - loss: 0.2534\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.9829 - loss: 0.2475\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.9830 - loss: 0.2343\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9707 - loss: 0.2451\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9736 - loss: 0.2479\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - accuracy: 0.9732 - loss: 0.2650\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - accuracy: 0.9680 - loss: 0.2621\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9706 - loss: 0.2458\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9794 - loss: 0.2300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a6eb50e7b80>"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "text = \"I am a software\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGeYGwCMfTus",
        "outputId": "e380281e-40b2-46aa-f168-c73257935e53"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "I am a software keep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "I am a software keep growing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "I am a software keep growing in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "I am a software keep growing in deep\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "I am a software keep growing in deep learning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "I am a software keep growing in deep learning and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "I am a software keep growing in deep learning and ai\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "I am a software keep growing in deep learning and ai focusing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "I am a software keep growing in deep learning and ai focusing on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "I am a software keep growing in deep learning and ai focusing on research\n"
          ]
        }
      ]
    }
  ]
}